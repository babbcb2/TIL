{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 2450205248711108345,\n",
       " name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 4971491488\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 3352311911140862131\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1660 Ti with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\"]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1\n",
      "2.4.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0\n",
      "4\n",
      "1\n",
      "9\n",
      "2\n",
      "1\n",
      "3\n",
      "1\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for idx in range(10) :\n",
    "    print(y_train[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "[0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for idx in range(10) :\n",
    "    print(y_train[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test  = x_test.reshape (10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000, 10), (10000, 784), (10000, 10))"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 모델만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add( keras.layers.Dense(256, activation='sigmoid',input_shape=(784, ), name='input' ) )\n",
    "\n",
    "model.add( keras.layers.Dense(128, activation='sigmoid', name='hidden1' ) )\n",
    "model.add( keras.layers.Dense(64, activation='sigmoid', name='hidden2' ) )\n",
    "model.add( keras.layers.Dense(32, activation='sigmoid', name='hidden3' ) )\n",
    "\n",
    "# 넬루 \n",
    "#\n",
    "#\n",
    "\n",
    "\n",
    "model.add( keras.layers.Dense(10, activation='softmax', name='output' ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (Dense)                (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "hidden1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "hidden3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 244,522\n",
      "Trainable params: 244,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델컴파인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (Dense)                (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "hidden1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "hidden3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 244,522\n",
      "Trainable params: 244,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate = 0.01)\n",
    "model.compile(optimizer = optimizer,\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 2.0377 - accuracy: 0.5080 - val_loss: 1.9793 - val_accuracy: 0.5208\n",
      "Epoch 2/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.9331 - accuracy: 0.5296 - val_loss: 1.8670 - val_accuracy: 0.5430\n",
      "Epoch 3/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.8160 - accuracy: 0.5580 - val_loss: 1.7418 - val_accuracy: 0.5734\n",
      "Epoch 4/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.6836 - accuracy: 0.5943 - val_loss: 1.6031 - val_accuracy: 0.6046\n",
      "Epoch 5/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.5397 - accuracy: 0.6303 - val_loss: 1.4587 - val_accuracy: 0.6587\n",
      "Epoch 6/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.3976 - accuracy: 0.6673 - val_loss: 1.3226 - val_accuracy: 0.6854\n",
      "Epoch 7/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.2671 - accuracy: 0.6938 - val_loss: 1.2005 - val_accuracy: 0.7105\n",
      "Epoch 8/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.1517 - accuracy: 0.7164 - val_loss: 1.0948 - val_accuracy: 0.7320\n",
      "Epoch 9/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 1.0535 - accuracy: 0.7390 - val_loss: 1.0054 - val_accuracy: 0.7520\n",
      "Epoch 10/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.9693 - accuracy: 0.7625 - val_loss: 0.9275 - val_accuracy: 0.7744\n",
      "Epoch 11/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.8969 - accuracy: 0.7829 - val_loss: 0.8613 - val_accuracy: 0.7965\n",
      "Epoch 12/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.8328 - accuracy: 0.8005 - val_loss: 0.8026 - val_accuracy: 0.8123\n",
      "Epoch 13/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.7772 - accuracy: 0.8163 - val_loss: 0.7526 - val_accuracy: 0.8257\n",
      "Epoch 14/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.7281 - accuracy: 0.8313 - val_loss: 0.7073 - val_accuracy: 0.8376\n",
      "Epoch 15/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.6848 - accuracy: 0.8426 - val_loss: 0.6669 - val_accuracy: 0.8517\n",
      "Epoch 16/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.6457 - accuracy: 0.8557 - val_loss: 0.6333 - val_accuracy: 0.8620\n",
      "Epoch 17/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.6108 - accuracy: 0.8658 - val_loss: 0.5999 - val_accuracy: 0.8718\n",
      "Epoch 18/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5781 - accuracy: 0.8746 - val_loss: 0.5703 - val_accuracy: 0.8787\n",
      "Epoch 19/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.5493 - accuracy: 0.8830 - val_loss: 0.5475 - val_accuracy: 0.8854\n",
      "Epoch 20/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.5219 - accuracy: 0.8905 - val_loss: 0.5224 - val_accuracy: 0.8914\n",
      "Epoch 21/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.4975 - accuracy: 0.8970 - val_loss: 0.5030 - val_accuracy: 0.8949\n",
      "Epoch 22/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4734 - accuracy: 0.9024 - val_loss: 0.4793 - val_accuracy: 0.8991\n",
      "Epoch 23/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4524 - accuracy: 0.9081 - val_loss: 0.4627 - val_accuracy: 0.9027\n",
      "Epoch 24/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4329 - accuracy: 0.9121 - val_loss: 0.4455 - val_accuracy: 0.9064\n",
      "Epoch 25/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.4140 - accuracy: 0.9157 - val_loss: 0.4269 - val_accuracy: 0.9096\n",
      "Epoch 26/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3972 - accuracy: 0.9190 - val_loss: 0.4131 - val_accuracy: 0.9116\n",
      "Epoch 27/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3802 - accuracy: 0.9222 - val_loss: 0.3997 - val_accuracy: 0.9147\n",
      "Epoch 28/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3637 - accuracy: 0.9268 - val_loss: 0.3831 - val_accuracy: 0.9191\n",
      "Epoch 29/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3494 - accuracy: 0.9292 - val_loss: 0.3697 - val_accuracy: 0.9192\n",
      "Epoch 30/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3369 - accuracy: 0.9315 - val_loss: 0.3616 - val_accuracy: 0.9244\n",
      "Epoch 31/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3220 - accuracy: 0.9347 - val_loss: 0.3480 - val_accuracy: 0.9254\n",
      "Epoch 32/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.3093 - accuracy: 0.9369 - val_loss: 0.3398 - val_accuracy: 0.9231\n",
      "Epoch 33/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2993 - accuracy: 0.9390 - val_loss: 0.3309 - val_accuracy: 0.9271\n",
      "Epoch 34/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2892 - accuracy: 0.9401 - val_loss: 0.3195 - val_accuracy: 0.9276\n",
      "Epoch 35/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2771 - accuracy: 0.9428 - val_loss: 0.3113 - val_accuracy: 0.9281\n",
      "Epoch 36/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2691 - accuracy: 0.9446 - val_loss: 0.3060 - val_accuracy: 0.9329\n",
      "Epoch 37/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2586 - accuracy: 0.9463 - val_loss: 0.2981 - val_accuracy: 0.9285\n",
      "Epoch 38/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2512 - accuracy: 0.9474 - val_loss: 0.2908 - val_accuracy: 0.9337\n",
      "Epoch 39/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2424 - accuracy: 0.9492 - val_loss: 0.2827 - val_accuracy: 0.9355\n",
      "Epoch 40/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.2355 - accuracy: 0.9500 - val_loss: 0.2775 - val_accuracy: 0.9364\n",
      "Epoch 41/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2273 - accuracy: 0.9518 - val_loss: 0.2720 - val_accuracy: 0.9366\n",
      "Epoch 42/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2226 - accuracy: 0.9527 - val_loss: 0.2701 - val_accuracy: 0.9363\n",
      "Epoch 43/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2151 - accuracy: 0.9542 - val_loss: 0.2624 - val_accuracy: 0.9376\n",
      "Epoch 44/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2111 - accuracy: 0.9548 - val_loss: 0.2568 - val_accuracy: 0.9371\n",
      "Epoch 45/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.2047 - accuracy: 0.9561 - val_loss: 0.2487 - val_accuracy: 0.9405\n",
      "Epoch 46/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1991 - accuracy: 0.9567 - val_loss: 0.2543 - val_accuracy: 0.9391\n",
      "Epoch 47/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1949 - accuracy: 0.9575 - val_loss: 0.2492 - val_accuracy: 0.9406\n",
      "Epoch 48/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1883 - accuracy: 0.9596 - val_loss: 0.2397 - val_accuracy: 0.9407\n",
      "Epoch 49/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1834 - accuracy: 0.9603 - val_loss: 0.2313 - val_accuracy: 0.9440\n",
      "Epoch 50/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1772 - accuracy: 0.9610 - val_loss: 0.2280 - val_accuracy: 0.9435\n",
      "Epoch 51/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1737 - accuracy: 0.9620 - val_loss: 0.2241 - val_accuracy: 0.9451\n",
      "Epoch 52/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1696 - accuracy: 0.9628 - val_loss: 0.2261 - val_accuracy: 0.9438\n",
      "Epoch 53/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1675 - accuracy: 0.9632 - val_loss: 0.2291 - val_accuracy: 0.9443\n",
      "Epoch 54/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1654 - accuracy: 0.9626 - val_loss: 0.2238 - val_accuracy: 0.9437\n",
      "Epoch 55/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1608 - accuracy: 0.9644 - val_loss: 0.2163 - val_accuracy: 0.9453\n",
      "Epoch 56/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1587 - accuracy: 0.9642 - val_loss: 0.2176 - val_accuracy: 0.9460\n",
      "Epoch 57/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1564 - accuracy: 0.9656 - val_loss: 0.2141 - val_accuracy: 0.9475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1522 - accuracy: 0.9660 - val_loss: 0.2093 - val_accuracy: 0.9478\n",
      "Epoch 59/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1488 - accuracy: 0.9669 - val_loss: 0.2093 - val_accuracy: 0.9490\n",
      "Epoch 60/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1471 - accuracy: 0.9672 - val_loss: 0.2065 - val_accuracy: 0.9470\n",
      "Epoch 61/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1436 - accuracy: 0.9678 - val_loss: 0.2070 - val_accuracy: 0.9486\n",
      "Epoch 62/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1384 - accuracy: 0.9686 - val_loss: 0.2058 - val_accuracy: 0.9476\n",
      "Epoch 63/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1364 - accuracy: 0.9698 - val_loss: 0.1986 - val_accuracy: 0.9511\n",
      "Epoch 64/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1331 - accuracy: 0.9700 - val_loss: 0.1979 - val_accuracy: 0.9470\n",
      "Epoch 65/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1305 - accuracy: 0.9710 - val_loss: 0.1987 - val_accuracy: 0.9505\n",
      "Epoch 66/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1301 - accuracy: 0.9707 - val_loss: 0.1966 - val_accuracy: 0.9471\n",
      "Epoch 67/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1289 - accuracy: 0.9706 - val_loss: 0.1930 - val_accuracy: 0.9502\n",
      "Epoch 68/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1253 - accuracy: 0.9715 - val_loss: 0.1931 - val_accuracy: 0.9506\n",
      "Epoch 69/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1232 - accuracy: 0.9718 - val_loss: 0.1965 - val_accuracy: 0.9489\n",
      "Epoch 70/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1190 - accuracy: 0.9724 - val_loss: 0.1908 - val_accuracy: 0.9504\n",
      "Epoch 71/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1163 - accuracy: 0.9742 - val_loss: 0.1909 - val_accuracy: 0.9498\n",
      "Epoch 72/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1150 - accuracy: 0.9743 - val_loss: 0.1885 - val_accuracy: 0.9506\n",
      "Epoch 73/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1113 - accuracy: 0.9753 - val_loss: 0.1837 - val_accuracy: 0.9511\n",
      "Epoch 74/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1109 - accuracy: 0.9747 - val_loss: 0.1853 - val_accuracy: 0.9528\n",
      "Epoch 75/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1124 - accuracy: 0.9738 - val_loss: 0.1849 - val_accuracy: 0.9514\n",
      "Epoch 76/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1096 - accuracy: 0.9753 - val_loss: 0.1816 - val_accuracy: 0.9534\n",
      "Epoch 77/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1096 - accuracy: 0.9749 - val_loss: 0.1873 - val_accuracy: 0.9513\n",
      "Epoch 78/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1082 - accuracy: 0.9751 - val_loss: 0.1834 - val_accuracy: 0.9534\n",
      "Epoch 79/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1051 - accuracy: 0.9759 - val_loss: 0.1833 - val_accuracy: 0.9504\n",
      "Epoch 80/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.1041 - accuracy: 0.9761 - val_loss: 0.1800 - val_accuracy: 0.9525\n",
      "Epoch 81/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1018 - accuracy: 0.9768 - val_loss: 0.1768 - val_accuracy: 0.9538\n",
      "Epoch 82/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.1005 - accuracy: 0.9766 - val_loss: 0.1800 - val_accuracy: 0.9505\n",
      "Epoch 83/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0998 - accuracy: 0.9773 - val_loss: 0.1780 - val_accuracy: 0.9537\n",
      "Epoch 84/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0957 - accuracy: 0.9779 - val_loss: 0.1728 - val_accuracy: 0.9533\n",
      "Epoch 85/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0933 - accuracy: 0.9795 - val_loss: 0.1692 - val_accuracy: 0.9567\n",
      "Epoch 86/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0920 - accuracy: 0.9793 - val_loss: 0.1738 - val_accuracy: 0.9536\n",
      "Epoch 87/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0912 - accuracy: 0.9793 - val_loss: 0.1689 - val_accuracy: 0.9557\n",
      "Epoch 88/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0900 - accuracy: 0.9799 - val_loss: 0.1747 - val_accuracy: 0.9546\n",
      "Epoch 89/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0886 - accuracy: 0.9808 - val_loss: 0.1743 - val_accuracy: 0.9554\n",
      "Epoch 90/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0874 - accuracy: 0.9794 - val_loss: 0.1697 - val_accuracy: 0.9566\n",
      "Epoch 91/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0880 - accuracy: 0.9799 - val_loss: 0.1687 - val_accuracy: 0.9557\n",
      "Epoch 92/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0851 - accuracy: 0.9808 - val_loss: 0.1722 - val_accuracy: 0.9551\n",
      "Epoch 93/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0832 - accuracy: 0.9818 - val_loss: 0.1723 - val_accuracy: 0.9538\n",
      "Epoch 94/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0833 - accuracy: 0.9809 - val_loss: 0.1702 - val_accuracy: 0.9539\n",
      "Epoch 95/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0796 - accuracy: 0.9824 - val_loss: 0.1696 - val_accuracy: 0.9553\n",
      "Epoch 96/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0796 - accuracy: 0.9824 - val_loss: 0.1726 - val_accuracy: 0.9551\n",
      "Epoch 97/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0793 - accuracy: 0.9820 - val_loss: 0.1726 - val_accuracy: 0.9538\n",
      "Epoch 98/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0780 - accuracy: 0.9826 - val_loss: 0.1696 - val_accuracy: 0.9564\n",
      "Epoch 99/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0737 - accuracy: 0.9840 - val_loss: 0.1629 - val_accuracy: 0.9558\n",
      "Epoch 100/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0742 - accuracy: 0.9836 - val_loss: 0.1688 - val_accuracy: 0.9555\n",
      "Epoch 101/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0744 - accuracy: 0.9833 - val_loss: 0.1727 - val_accuracy: 0.9553\n",
      "Epoch 102/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0731 - accuracy: 0.9834 - val_loss: 0.1708 - val_accuracy: 0.9532\n",
      "Epoch 103/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0745 - accuracy: 0.9836 - val_loss: 0.1700 - val_accuracy: 0.9558\n",
      "Epoch 104/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0707 - accuracy: 0.9842 - val_loss: 0.1655 - val_accuracy: 0.9556\n",
      "Epoch 105/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0677 - accuracy: 0.9852 - val_loss: 0.1653 - val_accuracy: 0.9545\n",
      "Epoch 106/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0655 - accuracy: 0.9856 - val_loss: 0.1632 - val_accuracy: 0.9554\n",
      "Epoch 107/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0645 - accuracy: 0.9862 - val_loss: 0.1645 - val_accuracy: 0.9563\n",
      "Epoch 108/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0652 - accuracy: 0.9859 - val_loss: 0.1633 - val_accuracy: 0.9554\n",
      "Epoch 109/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0653 - accuracy: 0.9858 - val_loss: 0.1606 - val_accuracy: 0.9559\n",
      "Epoch 110/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0647 - accuracy: 0.9855 - val_loss: 0.1604 - val_accuracy: 0.9574\n",
      "Epoch 111/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0633 - accuracy: 0.9867 - val_loss: 0.1641 - val_accuracy: 0.9580\n",
      "Epoch 112/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0649 - accuracy: 0.9855 - val_loss: 0.1624 - val_accuracy: 0.9572\n",
      "Epoch 113/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0623 - accuracy: 0.9861 - val_loss: 0.1658 - val_accuracy: 0.9556\n",
      "Epoch 114/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0642 - accuracy: 0.9850 - val_loss: 0.1623 - val_accuracy: 0.9586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0589 - accuracy: 0.9876 - val_loss: 0.1648 - val_accuracy: 0.9551\n",
      "Epoch 116/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0599 - accuracy: 0.9871 - val_loss: 0.1616 - val_accuracy: 0.9576\n",
      "Epoch 117/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0599 - accuracy: 0.9868 - val_loss: 0.1609 - val_accuracy: 0.9556\n",
      "Epoch 118/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0587 - accuracy: 0.9873 - val_loss: 0.1644 - val_accuracy: 0.9570\n",
      "Epoch 119/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0586 - accuracy: 0.9873 - val_loss: 0.1646 - val_accuracy: 0.9561\n",
      "Epoch 120/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0568 - accuracy: 0.9879 - val_loss: 0.1585 - val_accuracy: 0.9572\n",
      "Epoch 121/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0540 - accuracy: 0.9890 - val_loss: 0.1616 - val_accuracy: 0.9556\n",
      "Epoch 122/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0556 - accuracy: 0.9880 - val_loss: 0.1605 - val_accuracy: 0.9565\n",
      "Epoch 123/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0555 - accuracy: 0.9884 - val_loss: 0.1635 - val_accuracy: 0.9565\n",
      "Epoch 124/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0552 - accuracy: 0.9875 - val_loss: 0.1621 - val_accuracy: 0.9558\n",
      "Epoch 125/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0558 - accuracy: 0.9872 - val_loss: 0.1561 - val_accuracy: 0.9587\n",
      "Epoch 126/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0533 - accuracy: 0.9885 - val_loss: 0.1587 - val_accuracy: 0.9562\n",
      "Epoch 127/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0511 - accuracy: 0.9894 - val_loss: 0.1595 - val_accuracy: 0.9581\n",
      "Epoch 128/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0516 - accuracy: 0.9895 - val_loss: 0.1549 - val_accuracy: 0.9581\n",
      "Epoch 129/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0526 - accuracy: 0.9883 - val_loss: 0.1539 - val_accuracy: 0.9583\n",
      "Epoch 130/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0497 - accuracy: 0.9893 - val_loss: 0.1602 - val_accuracy: 0.9571\n",
      "Epoch 131/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0498 - accuracy: 0.9891 - val_loss: 0.1596 - val_accuracy: 0.9573\n",
      "Epoch 132/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0537 - accuracy: 0.9873 - val_loss: 0.1591 - val_accuracy: 0.9583\n",
      "Epoch 133/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0513 - accuracy: 0.9883 - val_loss: 0.1559 - val_accuracy: 0.9586\n",
      "Epoch 134/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0489 - accuracy: 0.9897 - val_loss: 0.1602 - val_accuracy: 0.9585\n",
      "Epoch 135/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0455 - accuracy: 0.9907 - val_loss: 0.1559 - val_accuracy: 0.9584\n",
      "Epoch 136/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0426 - accuracy: 0.9915 - val_loss: 0.1539 - val_accuracy: 0.9593\n",
      "Epoch 137/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0412 - accuracy: 0.9923 - val_loss: 0.1562 - val_accuracy: 0.9581\n",
      "Epoch 138/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0402 - accuracy: 0.9925 - val_loss: 0.1536 - val_accuracy: 0.9594\n",
      "Epoch 139/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0388 - accuracy: 0.9930 - val_loss: 0.1548 - val_accuracy: 0.9576\n",
      "Epoch 140/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0396 - accuracy: 0.9923 - val_loss: 0.1565 - val_accuracy: 0.9581\n",
      "Epoch 141/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0367 - accuracy: 0.9939 - val_loss: 0.1544 - val_accuracy: 0.9577\n",
      "Epoch 142/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0354 - accuracy: 0.9941 - val_loss: 0.1562 - val_accuracy: 0.9587\n",
      "Epoch 143/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0364 - accuracy: 0.9935 - val_loss: 0.1551 - val_accuracy: 0.9587\n",
      "Epoch 144/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0370 - accuracy: 0.9934 - val_loss: 0.1548 - val_accuracy: 0.9593\n",
      "Epoch 145/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0356 - accuracy: 0.9939 - val_loss: 0.1544 - val_accuracy: 0.9604\n",
      "Epoch 146/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0341 - accuracy: 0.9942 - val_loss: 0.1567 - val_accuracy: 0.9591\n",
      "Epoch 147/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0321 - accuracy: 0.9948 - val_loss: 0.1536 - val_accuracy: 0.9595\n",
      "Epoch 148/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0329 - accuracy: 0.9947 - val_loss: 0.1550 - val_accuracy: 0.9596\n",
      "Epoch 149/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0306 - accuracy: 0.9955 - val_loss: 0.1496 - val_accuracy: 0.9615\n",
      "Epoch 150/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0291 - accuracy: 0.9959 - val_loss: 0.1559 - val_accuracy: 0.9586\n",
      "Epoch 151/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0288 - accuracy: 0.9959 - val_loss: 0.1574 - val_accuracy: 0.9584\n",
      "Epoch 152/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0276 - accuracy: 0.9963 - val_loss: 0.1516 - val_accuracy: 0.9596\n",
      "Epoch 153/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0259 - accuracy: 0.9965 - val_loss: 0.1529 - val_accuracy: 0.9600\n",
      "Epoch 154/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0243 - accuracy: 0.9972 - val_loss: 0.1530 - val_accuracy: 0.9599\n",
      "Epoch 155/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0231 - accuracy: 0.9974 - val_loss: 0.1506 - val_accuracy: 0.9607\n",
      "Epoch 156/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0219 - accuracy: 0.9974 - val_loss: 0.1542 - val_accuracy: 0.9597\n",
      "Epoch 157/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0211 - accuracy: 0.9979 - val_loss: 0.1528 - val_accuracy: 0.9595\n",
      "Epoch 158/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0210 - accuracy: 0.9980 - val_loss: 0.1528 - val_accuracy: 0.9586\n",
      "Epoch 159/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0196 - accuracy: 0.9981 - val_loss: 0.1529 - val_accuracy: 0.9602\n",
      "Epoch 160/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0185 - accuracy: 0.9983 - val_loss: 0.1532 - val_accuracy: 0.9589\n",
      "Epoch 161/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0180 - accuracy: 0.9984 - val_loss: 0.1570 - val_accuracy: 0.9602\n",
      "Epoch 162/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0172 - accuracy: 0.9987 - val_loss: 0.1556 - val_accuracy: 0.9612\n",
      "Epoch 163/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0164 - accuracy: 0.9987 - val_loss: 0.1549 - val_accuracy: 0.9611\n",
      "Epoch 164/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0157 - accuracy: 0.9987 - val_loss: 0.1548 - val_accuracy: 0.9604\n",
      "Epoch 165/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0149 - accuracy: 0.9988 - val_loss: 0.1528 - val_accuracy: 0.9612\n",
      "Epoch 166/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0142 - accuracy: 0.9990 - val_loss: 0.1523 - val_accuracy: 0.9619\n",
      "Epoch 167/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0137 - accuracy: 0.9989 - val_loss: 0.1542 - val_accuracy: 0.9611\n",
      "Epoch 168/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0133 - accuracy: 0.9990 - val_loss: 0.1551 - val_accuracy: 0.9598\n",
      "Epoch 169/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0129 - accuracy: 0.9990 - val_loss: 0.1551 - val_accuracy: 0.9596\n",
      "Epoch 170/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0126 - accuracy: 0.9990 - val_loss: 0.1553 - val_accuracy: 0.9598\n",
      "Epoch 171/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0124 - accuracy: 0.9990 - val_loss: 0.1550 - val_accuracy: 0.9604\n",
      "Epoch 172/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0121 - accuracy: 0.9991 - val_loss: 0.1553 - val_accuracy: 0.9592\n",
      "Epoch 173/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0119 - accuracy: 0.9990 - val_loss: 0.1560 - val_accuracy: 0.9595\n",
      "Epoch 174/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0117 - accuracy: 0.9991 - val_loss: 0.1559 - val_accuracy: 0.9588\n",
      "Epoch 175/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0116 - accuracy: 0.9990 - val_loss: 0.1563 - val_accuracy: 0.9591\n",
      "Epoch 176/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0113 - accuracy: 0.9991 - val_loss: 0.1563 - val_accuracy: 0.9594\n",
      "Epoch 177/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0113 - accuracy: 0.9990 - val_loss: 0.1561 - val_accuracy: 0.9594\n",
      "Epoch 178/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0112 - accuracy: 0.9990 - val_loss: 0.1563 - val_accuracy: 0.9593\n",
      "Epoch 179/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0110 - accuracy: 0.9991 - val_loss: 0.1562 - val_accuracy: 0.9593\n",
      "Epoch 180/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0109 - accuracy: 0.9991 - val_loss: 0.1566 - val_accuracy: 0.9599\n",
      "Epoch 181/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0107 - accuracy: 0.9991 - val_loss: 0.1571 - val_accuracy: 0.9587\n",
      "Epoch 182/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0106 - accuracy: 0.9991 - val_loss: 0.1572 - val_accuracy: 0.9590\n",
      "Epoch 183/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0105 - accuracy: 0.9991 - val_loss: 0.1573 - val_accuracy: 0.9597\n",
      "Epoch 184/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0104 - accuracy: 0.9991 - val_loss: 0.1579 - val_accuracy: 0.9593\n",
      "Epoch 185/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0103 - accuracy: 0.9991 - val_loss: 0.1580 - val_accuracy: 0.9592\n",
      "Epoch 186/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0102 - accuracy: 0.9991 - val_loss: 0.1580 - val_accuracy: 0.9592\n",
      "Epoch 187/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0101 - accuracy: 0.9991 - val_loss: 0.1584 - val_accuracy: 0.9589\n",
      "Epoch 188/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0100 - accuracy: 0.9991 - val_loss: 0.1581 - val_accuracy: 0.9590\n",
      "Epoch 189/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0100 - accuracy: 0.9991 - val_loss: 0.1587 - val_accuracy: 0.9592\n",
      "Epoch 190/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0099 - accuracy: 0.9991 - val_loss: 0.1588 - val_accuracy: 0.9588\n",
      "Epoch 191/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0098 - accuracy: 0.9991 - val_loss: 0.1589 - val_accuracy: 0.9589\n",
      "Epoch 192/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0097 - accuracy: 0.9991 - val_loss: 0.1586 - val_accuracy: 0.9590\n",
      "Epoch 193/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0096 - accuracy: 0.9991 - val_loss: 0.1589 - val_accuracy: 0.9590\n",
      "Epoch 194/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0096 - accuracy: 0.9991 - val_loss: 0.1591 - val_accuracy: 0.9589\n",
      "Epoch 195/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0095 - accuracy: 0.9992 - val_loss: 0.1591 - val_accuracy: 0.9589\n",
      "Epoch 196/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0094 - accuracy: 0.9992 - val_loss: 0.1595 - val_accuracy: 0.9587\n",
      "Epoch 197/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0093 - accuracy: 0.9992 - val_loss: 0.1593 - val_accuracy: 0.9590\n",
      "Epoch 198/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0093 - accuracy: 0.9991 - val_loss: 0.1595 - val_accuracy: 0.9587\n",
      "Epoch 199/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0092 - accuracy: 0.9992 - val_loss: 0.1595 - val_accuracy: 0.9589\n",
      "Epoch 200/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0091 - accuracy: 0.9991 - val_loss: 0.1596 - val_accuracy: 0.9588\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size = 128, epochs = 200, validation_data = (x_test, y_test) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3024 - accuracy: 0.9263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3024339973926544, 0.9262999892234802]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 32928000 into shape (60000,28,28)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-143-c49afe1f06cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mx_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m60000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 32928000 into shape (60000,28,28)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_train = x_train.reshape(60000, 28, 28)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(x_train[0], cmap=plt.cm.binary)\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드부터 다시한번 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test  = x_test.reshape (10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000, 10), (10000, 784), (10000, 10))"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers    import Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping , ModelCheckpoint\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,\n",
    "                                                 test_size = 0.3,\n",
    "                                                 random_state = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 784), (18000, 784), (42000, 10), (18000, 10))"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_val.shape, y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 모델을 구성하는 두번째 방법\n",
    "- 함수형 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "input = Input(shape=(784,), name='input')\n",
    "\n",
    "hidden1 = Dense(256, activation='sigmoid', name='hidden1' )(input)\n",
    "hidden2 = Dense(128, activation='sigmoid', name='hidden2' )(hidden1)\n",
    "hidden3 = Dense(64, activation='sigmoid', name='hidden3' )(hidden2)\n",
    "hidden4 = Dense(32, activation='sigmoid', name='hidden4' )(hidden3)\n",
    "\n",
    "output = Dense(10, activation='softmax', name='output' )(hidden4)\n",
    "\n",
    "model = Model(inputs=[input], outputs = [output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 784)]             0         \n",
      "_________________________________________________________________\n",
      "hidden1 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "hidden3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "hidden4 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 244,522\n",
      "Trainable params: 244,522\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "optimizer = SGD(learning_rate = 0.01)\n",
    "model.compile(optimizer = optimizer,\n",
    "             loss = 'categorical_crossentropy',\n",
    "             metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 2.1747 - accuracy: 0.3416 - val_loss: 2.1529 - val_accuracy: 0.3434\n",
      "Epoch 2/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 2.1275 - accuracy: 0.3552 - val_loss: 2.0972 - val_accuracy: 0.3815\n",
      "Epoch 3/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 2.0640 - accuracy: 0.3677 - val_loss: 2.0256 - val_accuracy: 0.3969\n",
      "Epoch 4/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 1.9865 - accuracy: 0.3912 - val_loss: 1.9439 - val_accuracy: 0.3876\n",
      "Epoch 5/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 1.9034 - accuracy: 0.4081 - val_loss: 1.8609 - val_accuracy: 0.4388\n",
      "Epoch 6/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 1.8214 - accuracy: 0.4458 - val_loss: 1.7805 - val_accuracy: 0.4809\n",
      "Epoch 7/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 1.7418 - accuracy: 0.4924 - val_loss: 1.7023 - val_accuracy: 0.5309\n",
      "Epoch 8/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 1.6623 - accuracy: 0.5391 - val_loss: 1.6224 - val_accuracy: 0.5701\n",
      "Epoch 9/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 1.5796 - accuracy: 0.5794 - val_loss: 1.5385 - val_accuracy: 0.5969\n",
      "Epoch 10/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 1.4932 - accuracy: 0.6069 - val_loss: 1.4521 - val_accuracy: 0.6183\n",
      "Epoch 11/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 1.4061 - accuracy: 0.6271 - val_loss: 1.3678 - val_accuracy: 0.6444\n",
      "Epoch 12/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 1.3226 - accuracy: 0.6510 - val_loss: 1.2905 - val_accuracy: 0.6559\n",
      "Epoch 13/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 1.2470 - accuracy: 0.6684 - val_loss: 1.2200 - val_accuracy: 0.6769\n",
      "Epoch 14/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 1.1796 - accuracy: 0.6905 - val_loss: 1.1569 - val_accuracy: 0.6943\n",
      "Epoch 15/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 1.1198 - accuracy: 0.7078 - val_loss: 1.1028 - val_accuracy: 0.7210\n",
      "Epoch 16/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 1.0663 - accuracy: 0.7309 - val_loss: 1.0513 - val_accuracy: 0.7377\n",
      "Epoch 17/100\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 1.0170 - accuracy: 0.7507 - val_loss: 1.0070 - val_accuracy: 0.7514\n",
      "Epoch 18/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.9722 - accuracy: 0.7651 - val_loss: 0.9636 - val_accuracy: 0.7718\n",
      "Epoch 19/100\n",
      "329/329 [==============================] - 2s 5ms/step - loss: 0.9303 - accuracy: 0.7838 - val_loss: 0.9257 - val_accuracy: 0.7863\n",
      "Epoch 20/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.8919 - accuracy: 0.7970 - val_loss: 0.8898 - val_accuracy: 0.7997\n",
      "Epoch 21/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.8546 - accuracy: 0.8095 - val_loss: 0.8557 - val_accuracy: 0.8070\n",
      "Epoch 22/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.8202 - accuracy: 0.8205 - val_loss: 0.8239 - val_accuracy: 0.8155\n",
      "Epoch 23/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.7880 - accuracy: 0.8280 - val_loss: 0.7907 - val_accuracy: 0.8256\n",
      "Epoch 24/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.7563 - accuracy: 0.8400 - val_loss: 0.7663 - val_accuracy: 0.8288\n",
      "Epoch 25/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.7274 - accuracy: 0.8446 - val_loss: 0.7373 - val_accuracy: 0.8398\n",
      "Epoch 26/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.6992 - accuracy: 0.8545 - val_loss: 0.7124 - val_accuracy: 0.8451\n",
      "Epoch 27/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.6730 - accuracy: 0.8615 - val_loss: 0.6867 - val_accuracy: 0.8502\n",
      "Epoch 28/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.6481 - accuracy: 0.8663 - val_loss: 0.6680 - val_accuracy: 0.8518\n",
      "Epoch 29/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.6244 - accuracy: 0.8720 - val_loss: 0.6426 - val_accuracy: 0.8596\n",
      "Epoch 30/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.6017 - accuracy: 0.8770 - val_loss: 0.6224 - val_accuracy: 0.8633\n",
      "Epoch 31/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.5812 - accuracy: 0.8807 - val_loss: 0.6044 - val_accuracy: 0.8653\n",
      "Epoch 32/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.5608 - accuracy: 0.8853 - val_loss: 0.5852 - val_accuracy: 0.8712\n",
      "Epoch 33/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.5417 - accuracy: 0.8896 - val_loss: 0.5714 - val_accuracy: 0.8726\n",
      "Epoch 34/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.5251 - accuracy: 0.8921 - val_loss: 0.5520 - val_accuracy: 0.8776\n",
      "Epoch 35/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.5063 - accuracy: 0.8960 - val_loss: 0.5385 - val_accuracy: 0.8808\n",
      "Epoch 36/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.4910 - accuracy: 0.8990 - val_loss: 0.5218 - val_accuracy: 0.8836\n",
      "Epoch 37/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.4753 - accuracy: 0.9026 - val_loss: 0.5121 - val_accuracy: 0.8838\n",
      "Epoch 38/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.4620 - accuracy: 0.9052 - val_loss: 0.5013 - val_accuracy: 0.8860\n",
      "Epoch 39/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.4471 - accuracy: 0.9087 - val_loss: 0.4863 - val_accuracy: 0.8893\n",
      "Epoch 40/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.4323 - accuracy: 0.9105 - val_loss: 0.4790 - val_accuracy: 0.8913\n",
      "Epoch 41/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.4241 - accuracy: 0.9112 - val_loss: 0.4699 - val_accuracy: 0.8942\n",
      "Epoch 42/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.4115 - accuracy: 0.9145 - val_loss: 0.4577 - val_accuracy: 0.8964\n",
      "Epoch 43/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.4017 - accuracy: 0.9163 - val_loss: 0.4477 - val_accuracy: 0.8970\n",
      "Epoch 44/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.3900 - accuracy: 0.9188 - val_loss: 0.4393 - val_accuracy: 0.9003\n",
      "Epoch 45/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.3794 - accuracy: 0.9200 - val_loss: 0.4287 - val_accuracy: 0.9011\n",
      "Epoch 46/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.3696 - accuracy: 0.9224 - val_loss: 0.4185 - val_accuracy: 0.9026\n",
      "Epoch 47/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.3605 - accuracy: 0.9237 - val_loss: 0.4140 - val_accuracy: 0.9041\n",
      "Epoch 48/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.3505 - accuracy: 0.9262 - val_loss: 0.4039 - val_accuracy: 0.9067\n",
      "Epoch 49/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.3423 - accuracy: 0.9277 - val_loss: 0.3976 - val_accuracy: 0.9092\n",
      "Epoch 50/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.3331 - accuracy: 0.9296 - val_loss: 0.3921 - val_accuracy: 0.9084\n",
      "Epoch 51/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.3300 - accuracy: 0.9302 - val_loss: 0.3847 - val_accuracy: 0.9093\n",
      "Epoch 52/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.3206 - accuracy: 0.9323 - val_loss: 0.3809 - val_accuracy: 0.9122\n",
      "Epoch 53/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.3108 - accuracy: 0.9348 - val_loss: 0.3718 - val_accuracy: 0.9137\n",
      "Epoch 54/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.3031 - accuracy: 0.9359 - val_loss: 0.3688 - val_accuracy: 0.9128\n",
      "Epoch 55/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.2962 - accuracy: 0.9383 - val_loss: 0.3611 - val_accuracy: 0.9140\n",
      "Epoch 56/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.2902 - accuracy: 0.9390 - val_loss: 0.3572 - val_accuracy: 0.9152\n",
      "Epoch 57/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.2862 - accuracy: 0.9399 - val_loss: 0.3550 - val_accuracy: 0.9159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.2798 - accuracy: 0.9414 - val_loss: 0.3554 - val_accuracy: 0.9142\n",
      "Epoch 59/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.2745 - accuracy: 0.9409 - val_loss: 0.3434 - val_accuracy: 0.9173\n",
      "Epoch 60/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.2660 - accuracy: 0.9442 - val_loss: 0.3390 - val_accuracy: 0.9197\n",
      "Epoch 61/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.2590 - accuracy: 0.9452 - val_loss: 0.3336 - val_accuracy: 0.9177\n",
      "Epoch 62/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.2584 - accuracy: 0.9453 - val_loss: 0.3288 - val_accuracy: 0.9199\n",
      "Epoch 63/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.2529 - accuracy: 0.9460 - val_loss: 0.3277 - val_accuracy: 0.9219\n",
      "Epoch 64/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.2448 - accuracy: 0.9477 - val_loss: 0.3208 - val_accuracy: 0.9224\n",
      "Epoch 65/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.2403 - accuracy: 0.9490 - val_loss: 0.3202 - val_accuracy: 0.9231\n",
      "Epoch 66/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.2373 - accuracy: 0.9501 - val_loss: 0.3202 - val_accuracy: 0.9221\n",
      "Epoch 67/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.2312 - accuracy: 0.9514 - val_loss: 0.3109 - val_accuracy: 0.9247\n",
      "Epoch 68/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.2273 - accuracy: 0.9520 - val_loss: 0.3073 - val_accuracy: 0.9253\n",
      "Epoch 69/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.2214 - accuracy: 0.9537 - val_loss: 0.3039 - val_accuracy: 0.9254\n",
      "Epoch 70/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.2166 - accuracy: 0.9546 - val_loss: 0.3006 - val_accuracy: 0.9262\n",
      "Epoch 71/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.2147 - accuracy: 0.9558 - val_loss: 0.3104 - val_accuracy: 0.9235\n",
      "Epoch 72/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.2105 - accuracy: 0.9558 - val_loss: 0.2974 - val_accuracy: 0.9259\n",
      "Epoch 73/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.2047 - accuracy: 0.9571 - val_loss: 0.2955 - val_accuracy: 0.9276\n",
      "Epoch 74/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.2028 - accuracy: 0.9568 - val_loss: 0.2956 - val_accuracy: 0.9253\n",
      "Epoch 75/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.1968 - accuracy: 0.9587 - val_loss: 0.2915 - val_accuracy: 0.9281\n",
      "Epoch 76/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.1916 - accuracy: 0.9602 - val_loss: 0.2862 - val_accuracy: 0.9283\n",
      "Epoch 77/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.1891 - accuracy: 0.9608 - val_loss: 0.2838 - val_accuracy: 0.9294\n",
      "Epoch 78/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.1849 - accuracy: 0.9620 - val_loss: 0.2837 - val_accuracy: 0.9299\n",
      "Epoch 79/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.1784 - accuracy: 0.9641 - val_loss: 0.2771 - val_accuracy: 0.9301\n",
      "Epoch 80/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.1778 - accuracy: 0.9640 - val_loss: 0.2782 - val_accuracy: 0.9302\n",
      "Epoch 81/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.1750 - accuracy: 0.9641 - val_loss: 0.2700 - val_accuracy: 0.9323\n",
      "Epoch 82/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.1745 - accuracy: 0.9635 - val_loss: 0.2717 - val_accuracy: 0.9328\n",
      "Epoch 83/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.1708 - accuracy: 0.9644 - val_loss: 0.2692 - val_accuracy: 0.9320\n",
      "Epoch 84/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.1667 - accuracy: 0.9664 - val_loss: 0.2698 - val_accuracy: 0.9319\n",
      "Epoch 85/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.1646 - accuracy: 0.9661 - val_loss: 0.2688 - val_accuracy: 0.9331\n",
      "Epoch 86/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.1623 - accuracy: 0.9660 - val_loss: 0.2694 - val_accuracy: 0.9306\n",
      "Epoch 87/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.1611 - accuracy: 0.9663 - val_loss: 0.2622 - val_accuracy: 0.9347\n",
      "Epoch 88/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.1563 - accuracy: 0.9672 - val_loss: 0.2677 - val_accuracy: 0.9331\n",
      "Epoch 89/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.1577 - accuracy: 0.9669 - val_loss: 0.2624 - val_accuracy: 0.9331\n",
      "Epoch 90/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.1501 - accuracy: 0.9694 - val_loss: 0.2540 - val_accuracy: 0.9359\n",
      "Epoch 91/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.1466 - accuracy: 0.9703 - val_loss: 0.2596 - val_accuracy: 0.9352\n",
      "Epoch 92/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.1443 - accuracy: 0.9705 - val_loss: 0.2543 - val_accuracy: 0.9359\n",
      "Epoch 93/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.1390 - accuracy: 0.9717 - val_loss: 0.2536 - val_accuracy: 0.9351\n",
      "Epoch 94/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.1406 - accuracy: 0.9709 - val_loss: 0.2519 - val_accuracy: 0.9362\n",
      "Epoch 95/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.1360 - accuracy: 0.9732 - val_loss: 0.2485 - val_accuracy: 0.9358\n",
      "Epoch 96/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.1299 - accuracy: 0.9751 - val_loss: 0.2473 - val_accuracy: 0.9354\n",
      "Epoch 97/100\n",
      "329/329 [==============================] - 1s 3ms/step - loss: 0.1298 - accuracy: 0.9743 - val_loss: 0.2481 - val_accuracy: 0.9348\n",
      "Epoch 98/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.1307 - accuracy: 0.9734 - val_loss: 0.2483 - val_accuracy: 0.9352\n",
      "Epoch 99/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.1286 - accuracy: 0.9743 - val_loss: 0.2506 - val_accuracy: 0.9354\n",
      "Epoch 100/100\n",
      "329/329 [==============================] - 1s 4ms/step - loss: 0.1267 - accuracy: 0.9749 - val_loss: 0.2447 - val_accuracy: 0.9357\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size = 128, epochs = 100, validation_data = (x_val, y_val) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "\n",
    "loss     = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15593426dc0>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax01 = fig.add_subplot(1,2,1)\n",
    "\n",
    "epochs = range(1, len(loss)+1)\n",
    "\n",
    "ax01.plot(epochs, loss     , color='blue', label='train loss')\n",
    "ax01.plot(epochs, val_loss , color='red',  label='val loss')\n",
    "ax01.set_xlabel('Epoch')\n",
    "ax01.set_ylabel('Loss')\n",
    "ax01.grid()\n",
    "ax01.legend()\n",
    "\n",
    "\n",
    "acc     = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "\n",
    "ax02 = fig.add_subplot(1,2,2)\n",
    "ax02.plot(epochs, acc     , color='blue', label='train acc')\n",
    "ax02.plot(epochs, val_acc , color='red',  label='val acc')\n",
    "ax02.set_xlabel('Epoch')\n",
    "ax02.set_ylabel('Acc')\n",
    "ax02.grid()\n",
    "ax02.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.7699 - accuracy: 0.8401\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7699249982833862, 0.8400999903678894]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
