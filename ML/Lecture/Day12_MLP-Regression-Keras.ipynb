{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import boston_housing\n",
    "from tensorflow.keras.layers import Input, Dense, Activation\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing   import StandardScaler, MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas  as pd\n",
    "import numpy   as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((303, 13), (102, 13), (303,), (102,))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.23247,   0.     ,   8.14   ,   0.     ,   0.538  ,   6.142  ,\n",
       "        91.7    ,   3.9769 ,   4.     , 307.     ,  21.     , 396.9    ,\n",
       "        18.72   ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add (Dense(10, input_shape=(13, )))\n",
    "model.add ( Activation('sigmoid'))\n",
    "\n",
    "model.add (Dense(8, activation='sigmoid'))\n",
    "model.add (Dense(6, activation='sigmoid'))\n",
    "model.add (Dense(4, activation='sigmoid'))\n",
    "\n",
    "model.add (Dense(1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                140       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 28        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 315\n",
      "Trainable params: 315\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mse',\n",
    "              optimizer = Adam(learning_rate=0.02),\n",
    "              metrics = ['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                140       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 88        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 28        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 315\n",
      "Trainable params: 315\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 1s 26ms/step - loss: 569.7626 - mse: 569.7626 - val_loss: 532.1303 - val_mse: 532.1303\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 475.1962 - mse: 475.1962 - val_loss: 490.9485 - val_mse: 490.9485\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 454.2357 - mse: 454.2357 - val_loss: 455.4919 - val_mse: 455.4919\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 395.0113 - mse: 395.0113 - val_loss: 425.0245 - val_mse: 425.0245\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 387.7714 - mse: 387.7714 - val_loss: 398.0696 - val_mse: 398.0696\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 359.8726 - mse: 359.8726 - val_loss: 373.0233 - val_mse: 373.0233\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 355.0748 - mse: 355.0748 - val_loss: 349.6148 - val_mse: 349.6148\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 321.2216 - mse: 321.2216 - val_loss: 327.1498 - val_mse: 327.1498\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 289.7444 - mse: 289.7444 - val_loss: 303.6048 - val_mse: 303.6048\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 279.5644 - mse: 279.5644 - val_loss: 271.3220 - val_mse: 271.3220\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 243.9002 - mse: 243.9002 - val_loss: 242.3908 - val_mse: 242.3908\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 215.9598 - mse: 215.9598 - val_loss: 218.9587 - val_mse: 218.9587\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 217.1251 - mse: 217.1251 - val_loss: 199.3993 - val_mse: 199.3993\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 196.9006 - mse: 196.9006 - val_loss: 182.9956 - val_mse: 182.9956\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 166.2884 - mse: 166.2884 - val_loss: 169.5891 - val_mse: 169.5891\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 140.7476 - mse: 140.7476 - val_loss: 157.7336 - val_mse: 157.7336\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 146.1643 - mse: 146.1643 - val_loss: 146.1236 - val_mse: 146.1236\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 135.0980 - mse: 135.0980 - val_loss: 136.5726 - val_mse: 136.5726\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 127.4591 - mse: 127.4591 - val_loss: 129.0468 - val_mse: 129.0468\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 113.1476 - mse: 113.1476 - val_loss: 122.4200 - val_mse: 122.4200\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 106.8840 - mse: 106.8840 - val_loss: 116.3098 - val_mse: 116.3098\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 121.8263 - mse: 121.8263 - val_loss: 111.2536 - val_mse: 111.2536\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - ETA: 0s - loss: 111.1087 - mse: 111.108 - 0s 7ms/step - loss: 103.8741 - mse: 103.8741 - val_loss: 107.1074 - val_mse: 107.1074\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 102.1700 - mse: 102.1700 - val_loss: 103.5246 - val_mse: 103.5246\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 103.4893 - mse: 103.4893 - val_loss: 100.5233 - val_mse: 100.5233\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 93.7677 - mse: 93.7677 - val_loss: 98.0193 - val_mse: 98.0193\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 99.3578 - mse: 99.3578 - val_loss: 95.8641 - val_mse: 95.8641\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 104.9469 - mse: 104.9469 - val_loss: 94.0659 - val_mse: 94.0659\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 82.5484 - mse: 82.5484 - val_loss: 92.6021 - val_mse: 92.6021\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 95.3998 - mse: 95.3998 - val_loss: 91.2592 - val_mse: 91.2592\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 85.7854 - mse: 85.7854 - val_loss: 90.1532 - val_mse: 90.1532\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 81.1602 - mse: 81.1602 - val_loss: 89.3212 - val_mse: 89.3212\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 87.8827 - mse: 87.8827 - val_loss: 88.5550 - val_mse: 88.5550\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 83.8364 - mse: 83.8364 - val_loss: 87.8755 - val_mse: 87.8755\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 89.3178 - mse: 89.3178 - val_loss: 87.2815 - val_mse: 87.2815\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 82.5554 - mse: 82.5554 - val_loss: 86.7200 - val_mse: 86.7200\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 79.2744 - mse: 79.2744 - val_loss: 86.2351 - val_mse: 86.2351\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 92.5313 - mse: 92.5313 - val_loss: 85.6180 - val_mse: 85.6180\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 80.7711 - mse: 80.7711 - val_loss: 85.3276 - val_mse: 85.3276\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 87.1093 - mse: 87.1093 - val_loss: 85.1376 - val_mse: 85.1376\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 84.6530 - mse: 84.6530 - val_loss: 84.9579 - val_mse: 84.9579\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 85.7119 - mse: 85.7119 - val_loss: 84.7799 - val_mse: 84.7799\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 94.1033 - mse: 94.1033 - val_loss: 84.5746 - val_mse: 84.5746\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 84.7879 - mse: 84.7879 - val_loss: 84.3950 - val_mse: 84.3950\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 90.0708 - mse: 90.0708 - val_loss: 84.2162 - val_mse: 84.2162\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 83.2315 - mse: 83.2315 - val_loss: 84.1125 - val_mse: 84.1125\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 83.3126 - mse: 83.3126 - val_loss: 84.1015 - val_mse: 84.1015\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 92.2046 - mse: 92.2046 - val_loss: 84.0759 - val_mse: 84.0759\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 9ms/step - loss: 83.2265 - mse: 83.2265 - val_loss: 84.0111 - val_mse: 84.0111\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 83.0131 - mse: 83.0131 - val_loss: 83.9403 - val_mse: 83.9403\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 82.6530 - mse: 82.6530 - val_loss: 83.8902 - val_mse: 83.8902\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 91.5836 - mse: 91.5836 - val_loss: 83.8195 - val_mse: 83.8195\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 98.7717 - mse: 98.7717 - val_loss: 83.8034 - val_mse: 83.8034\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 84.4962 - mse: 84.4962 - val_loss: 83.8530 - val_mse: 83.8530\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 85.7969 - mse: 85.7969 - val_loss: 83.9035 - val_mse: 83.9035\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 80.3186 - mse: 80.3186 - val_loss: 83.9578 - val_mse: 83.9578\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 81.4282 - mse: 81.4282 - val_loss: 83.9030 - val_mse: 83.9030\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 81.0271 - mse: 81.0271 - val_loss: 83.8393 - val_mse: 83.8393\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 93.0344 - mse: 93.0344 - val_loss: 83.7829 - val_mse: 83.7829\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 80.1771 - mse: 80.1771 - val_loss: 83.7272 - val_mse: 83.7272\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 79.1824 - mse: 79.1824 - val_loss: 83.7097 - val_mse: 83.7097\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 82.4421 - mse: 82.4421 - val_loss: 83.7108 - val_mse: 83.7108\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 90.9959 - mse: 90.9959 - val_loss: 83.7059 - val_mse: 83.7059\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 86.7735 - mse: 86.7735 - val_loss: 83.7347 - val_mse: 83.7347\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 83.5662 - mse: 83.5662 - val_loss: 83.7018 - val_mse: 83.7018\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 85.2373 - mse: 85.2373 - val_loss: 83.5905 - val_mse: 83.5905\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 74.3210 - mse: 74.3210 - val_loss: 83.4827 - val_mse: 83.4827\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 82.5156 - mse: 82.5156 - val_loss: 83.5091 - val_mse: 83.5091\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 85.1817 - mse: 85.1817 - val_loss: 83.5028 - val_mse: 83.5028\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 76.1841 - mse: 76.1841 - val_loss: 83.4909 - val_mse: 83.4909\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 84.8769 - mse: 84.8769 - val_loss: 83.5003 - val_mse: 83.5003\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 92.5810 - mse: 92.5810 - val_loss: 83.5604 - val_mse: 83.5604\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 91.0946 - mse: 91.0946 - val_loss: 83.6207 - val_mse: 83.6207\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 85.5281 - mse: 85.5281 - val_loss: 83.7149 - val_mse: 83.7149\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 82.3236 - mse: 82.3236 - val_loss: 83.7736 - val_mse: 83.7736\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 93.1037 - mse: 93.1037 - val_loss: 83.7570 - val_mse: 83.7570\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 87.9601 - mse: 87.9601 - val_loss: 83.8470 - val_mse: 83.8470\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 90.6207 - mse: 90.6207 - val_loss: 83.9235 - val_mse: 83.9235\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 75.4225 - mse: 75.4225 - val_loss: 83.9190 - val_mse: 83.9190\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 78.0307 - mse: 78.0307 - val_loss: 83.8487 - val_mse: 83.8487\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 86.5524 - mse: 86.5524 - val_loss: 83.7879 - val_mse: 83.7879\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 78.2860 - mse: 78.2860 - val_loss: 83.8289 - val_mse: 83.8289\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 89.8997 - mse: 89.8997 - val_loss: 83.8208 - val_mse: 83.8208\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 78.6771 - mse: 78.6771 - val_loss: 83.8716 - val_mse: 83.8716\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 80.6708 - mse: 80.6708 - val_loss: 83.7150 - val_mse: 83.7150\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 81.6278 - mse: 81.6278 - val_loss: 83.6305 - val_mse: 83.6305\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 85.6794 - mse: 85.6794 - val_loss: 83.4669 - val_mse: 83.4669\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 90.4459 - mse: 90.4459 - val_loss: 83.4359 - val_mse: 83.4359\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 85.7512 - mse: 85.7512 - val_loss: 83.4676 - val_mse: 83.4676\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 79.2629 - mse: 79.2629 - val_loss: 83.5001 - val_mse: 83.5001\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 85.7180 - mse: 85.7180 - val_loss: 83.5738 - val_mse: 83.5738\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 79.2505 - mse: 79.2505 - val_loss: 83.7278 - val_mse: 83.7278\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 86.3846 - mse: 86.3846 - val_loss: 83.8821 - val_mse: 83.8821\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 82.5043 - mse: 82.5043 - val_loss: 84.0294 - val_mse: 84.0294\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 89.5917 - mse: 89.5917 - val_loss: 84.0714 - val_mse: 84.0714\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 85.4653 - mse: 85.4653 - val_loss: 84.0439 - val_mse: 84.0439\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 77.4981 - mse: 77.4981 - val_loss: 84.0238 - val_mse: 84.0238\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 81.6839 - mse: 81.6839 - val_loss: 83.9445 - val_mse: 83.9445\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 7ms/step - loss: 82.5186 - mse: 82.5187 - val_loss: 84.0297 - val_mse: 84.0297\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 8ms/step - loss: 71.2363 - mse: 71.2363 - val_loss: 84.1177 - val_mse: 84.1177\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size = 50, epochs = 100, validation_data = (X_test, y_test), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6340 - mse: 84.6340\n",
      "Epoch 2/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6370 - mse: 84.6370\n",
      "Epoch 3/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6493 - mse: 84.6492\n",
      "Epoch 4/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.8267 - mse: 84.8267\n",
      "Epoch 5/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.7592 - mse: 84.7592\n",
      "Epoch 6/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.7020 - mse: 84.7020\n",
      "Epoch 7/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6918 - mse: 84.6918\n",
      "Epoch 8/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6244 - mse: 84.6244\n",
      "Epoch 9/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6388 - mse: 84.6388\n",
      "Epoch 10/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6261 - mse: 84.6261\n",
      "Epoch 11/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6285 - mse: 84.6285\n",
      "Epoch 12/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6647 - mse: 84.6647\n",
      "Epoch 13/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6432 - mse: 84.6432\n",
      "Epoch 14/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6551 - mse: 84.6551\n",
      "Epoch 15/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.7285 - mse: 84.7285\n",
      "Epoch 16/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6347 - mse: 84.6347\n",
      "Epoch 17/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6514 - mse: 84.6514\n",
      "Epoch 18/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6122 - mse: 84.6122\n",
      "Epoch 19/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.5939 - mse: 84.5939\n",
      "Epoch 20/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.8760 - mse: 84.8760\n",
      "Epoch 21/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 84.7851 - mse: 84.7851\n",
      "Epoch 22/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.7861 - mse: 84.7861\n",
      "Epoch 23/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.7848 - mse: 84.7848\n",
      "Epoch 24/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 84.8164 - mse: 84.8164\n",
      "Epoch 25/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6590 - mse: 84.6590\n",
      "Epoch 26/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6517 - mse: 84.6517\n",
      "Epoch 27/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6304 - mse: 84.6304\n",
      "Epoch 28/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6279 - mse: 84.6279\n",
      "Epoch 29/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6284 - mse: 84.6284\n",
      "Epoch 30/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 84.6370 - mse: 84.6370\n",
      "Epoch 31/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 84.6388 - mse: 84.6388\n",
      "Epoch 32/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 84.6346 - mse: 84.6346\n",
      "Epoch 33/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.8886 - mse: 84.8886\n",
      "Epoch 34/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.7493 - mse: 84.7493\n",
      "Epoch 35/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.7234 - mse: 84.7234\n",
      "Epoch 36/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6492 - mse: 84.6492\n",
      "Epoch 37/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6832 - mse: 84.6832\n",
      "Epoch 38/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6259 - mse: 84.6259\n",
      "Epoch 39/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6540 - mse: 84.6540\n",
      "Epoch 40/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.7497 - mse: 84.7497\n",
      "Epoch 41/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6311 - mse: 84.6311\n",
      "Epoch 42/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6388 - mse: 84.6388\n",
      "Epoch 43/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6457 - mse: 84.6457\n",
      "Epoch 44/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 84.6395 - mse: 84.6395\n",
      "Epoch 45/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6356 - mse: 84.6356\n",
      "Epoch 46/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6601 - mse: 84.6601\n",
      "Epoch 47/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6937 - mse: 84.6937\n",
      "Epoch 48/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6498 - mse: 84.6498\n",
      "Epoch 49/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6259 - mse: 84.6259\n",
      "Epoch 50/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6644 - mse: 84.6644\n",
      "Epoch 51/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6791 - mse: 84.6791\n",
      "Epoch 52/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.9273 - mse: 84.9273\n",
      "Epoch 53/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.7639 - mse: 84.7639\n",
      "Epoch 54/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.5827 - mse: 84.5827\n",
      "Epoch 55/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6282 - mse: 84.6282\n",
      "Epoch 56/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6440 - mse: 84.6440\n",
      "Epoch 57/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6551 - mse: 84.6551\n",
      "Epoch 58/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6247 - mse: 84.6247\n",
      "Epoch 59/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6375 - mse: 84.6375\n",
      "Epoch 60/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6321 - mse: 84.6321\n",
      "Epoch 61/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6485 - mse: 84.6485\n",
      "Epoch 62/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6833 - mse: 84.6833\n",
      "Epoch 63/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6415 - mse: 84.6415\n",
      "Epoch 64/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6966 - mse: 84.6966\n",
      "Epoch 65/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 84.7048 - mse: 84.7048\n",
      "Epoch 66/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.8363 - mse: 84.8363\n",
      "Epoch 67/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.8007 - mse: 84.8007\n",
      "Epoch 68/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.7329 - mse: 84.7329\n",
      "Epoch 69/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.7149 - mse: 84.7150\n",
      "Epoch 70/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6945 - mse: 84.6945\n",
      "Epoch 71/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 84.6842 - mse: 84.6842\n",
      "Epoch 72/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6621 - mse: 84.6621\n",
      "Epoch 73/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6257 - mse: 84.6257\n",
      "Epoch 74/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 84.6124 - mse: 84.6124\n",
      "Epoch 75/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6491 - mse: 84.6491\n",
      "Epoch 76/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6413 - mse: 84.6413\n",
      "Epoch 77/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6838 - mse: 84.6838\n",
      "Epoch 78/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6456 - mse: 84.6456\n",
      "Epoch 79/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6430 - mse: 84.6430\n",
      "Epoch 80/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 84.6635 - mse: 84.6635\n",
      "Epoch 81/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6201 - mse: 84.6201\n",
      "Epoch 82/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6377 - mse: 84.6377\n",
      "Epoch 83/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.7013 - mse: 84.7013\n",
      "Epoch 84/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6415 - mse: 84.6415\n",
      "Epoch 85/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6125 - mse: 84.6125\n",
      "Epoch 86/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 84.6295 - mse: 84.6295\n",
      "Epoch 87/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6203 - mse: 84.6203\n",
      "Epoch 88/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6868 - mse: 84.6868\n",
      "Epoch 89/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6628 - mse: 84.6628\n",
      "Epoch 90/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 84.6588 - mse: 84.6588\n",
      "Epoch 91/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6444 - mse: 84.6444\n",
      "Epoch 92/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 84.6402 - mse: 84.6402\n",
      "Epoch 93/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 84.6689 - mse: 84.6689\n",
      "Epoch 94/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 84.6777 - mse: 84.6777\n",
      "Epoch 95/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6758 - mse: 84.6758\n",
      "Epoch 96/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6585 - mse: 84.6585\n",
      "Epoch 97/100\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 84.6147 - mse: 84.6147\n",
      "Epoch 98/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.7080 - mse: 84.7080\n",
      "Epoch 99/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.7822 - mse: 84.7822\n",
      "Epoch 100/100\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 84.6957 - mse: 84.6957\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1fe1094ea90>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size = 50, epochs = 100, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 83.7473 - mse: 83.7473\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[83.74725341796875, 83.74725341796875]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mse', 'val_loss', 'val_mse'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 84.1177 - mse: 84.1177\n",
      "loss : 84.11767578125\n",
      "mse  : 84.11767578125\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(X_test, y_test)\n",
    "print ('loss :', result[0])\n",
    "print ('mse  :', result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   \n",
    "# 1. \n",
    "# 2.  ,   \n",
    "# 3.  , activation = 'relu' ,  optimiaer = SGD\n",
    "# 4. ,  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_raw, y_train_raw), (X_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaler = scaler.fit_transform (X_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.27224633, -0.48361547, -0.43576161, -0.25683275, -0.1652266 ,\n",
       "       -0.1764426 ,  0.81306188,  0.1166983 , -0.62624905, -0.59517003,\n",
       "        1.14850044,  0.44807713,  0.8252202 ])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaler[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_test_scaler = scaler.fit_transform (X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_scaler, y_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add (Dense(128, input_shape=(13, ), activation='relu'))\n",
    "\n",
    "model.add (Dense(64, activation='relu'))\n",
    "model.add (Dense(32, activation='relu'))\n",
    "\n",
    "model.add (Dense(1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 128)               1792      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 12,161\n",
      "Trainable params: 12,161\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mse',\n",
    "              optimizer = Adam(learning_rate=0.02),\n",
    "              metrics = ['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 1.2534 - mse: 1.2534 - val_loss: 14.0243 - val_mse: 14.0243\n",
      "Epoch 2/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.2859 - mse: 1.2859 - val_loss: 12.5721 - val_mse: 12.5721\n",
      "Epoch 3/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.4885 - mse: 1.4885 - val_loss: 17.8502 - val_mse: 17.8502\n",
      "Epoch 4/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.5372 - mse: 2.5372 - val_loss: 16.2267 - val_mse: 16.2267\n",
      "Epoch 5/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 4.8095 - mse: 4.8095 - val_loss: 17.6953 - val_mse: 17.6953\n",
      "Epoch 6/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 8.2140 - mse: 8.2140 - val_loss: 9.0492 - val_mse: 9.0492\n",
      "Epoch 7/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 6.8798 - mse: 6.8798 - val_loss: 15.8173 - val_mse: 15.8173\n",
      "Epoch 8/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 6.1642 - mse: 6.1642 - val_loss: 10.1162 - val_mse: 10.1162\n",
      "Epoch 9/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 4.6663 - mse: 4.6663 - val_loss: 13.2020 - val_mse: 13.2020\n",
      "Epoch 10/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 3.0852 - mse: 3.0852 - val_loss: 17.5314 - val_mse: 17.5314\n",
      "Epoch 11/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.7074 - mse: 2.7074 - val_loss: 12.7601 - val_mse: 12.7601\n",
      "Epoch 12/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.2503 - mse: 2.2503 - val_loss: 15.4627 - val_mse: 15.4627\n",
      "Epoch 13/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 4.8679 - mse: 4.8679 - val_loss: 14.4643 - val_mse: 14.4643\n",
      "Epoch 14/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 4.5433 - mse: 4.5433 - val_loss: 19.1675 - val_mse: 19.1675\n",
      "Epoch 15/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 8.4318 - mse: 8.4318 - val_loss: 10.9504 - val_mse: 10.9504\n",
      "Epoch 16/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 3.4816 - mse: 3.4816 - val_loss: 23.3846 - val_mse: 23.3846\n",
      "Epoch 17/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 4.3610 - mse: 4.3610 - val_loss: 13.6680 - val_mse: 13.6680\n",
      "Epoch 18/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.2058 - mse: 2.2058 - val_loss: 10.4012 - val_mse: 10.4012\n",
      "Epoch 19/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.3473 - mse: 2.3473 - val_loss: 13.2309 - val_mse: 13.2309\n",
      "Epoch 20/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.3811 - mse: 2.3811 - val_loss: 12.6565 - val_mse: 12.6565\n",
      "Epoch 21/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.8373 - mse: 1.8373 - val_loss: 17.2775 - val_mse: 17.2775\n",
      "Epoch 22/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 3.0327 - mse: 3.0327 - val_loss: 12.5136 - val_mse: 12.5136\n",
      "Epoch 23/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.8455 - mse: 2.8455 - val_loss: 14.0733 - val_mse: 14.0733\n",
      "Epoch 24/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.0563 - mse: 2.0563 - val_loss: 11.3926 - val_mse: 11.3926\n",
      "Epoch 25/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.8040 - mse: 1.8040 - val_loss: 14.6714 - val_mse: 14.6714\n",
      "Epoch 26/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.4658 - mse: 1.4658 - val_loss: 15.0845 - val_mse: 15.0845\n",
      "Epoch 27/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.3664 - mse: 1.3664 - val_loss: 14.2513 - val_mse: 14.2513\n",
      "Epoch 28/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.2028 - mse: 1.2028 - val_loss: 12.8465 - val_mse: 12.8465\n",
      "Epoch 29/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.2483 - mse: 1.2483 - val_loss: 13.3095 - val_mse: 13.3095\n",
      "Epoch 30/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.8781 - mse: 1.8781 - val_loss: 12.2833 - val_mse: 12.2833\n",
      "Epoch 31/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.1452 - mse: 2.1452 - val_loss: 13.6153 - val_mse: 13.6153\n",
      "Epoch 32/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.9243 - mse: 2.9243 - val_loss: 13.8262 - val_mse: 13.8262\n",
      "Epoch 33/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 3.2090 - mse: 3.2090 - val_loss: 19.2521 - val_mse: 19.2521\n",
      "Epoch 34/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 3.0482 - mse: 3.0482 - val_loss: 12.0200 - val_mse: 12.0200\n",
      "Epoch 35/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.3565 - mse: 2.3565 - val_loss: 13.2879 - val_mse: 13.2879\n",
      "Epoch 36/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.2063 - mse: 2.2063 - val_loss: 14.0738 - val_mse: 14.0738\n",
      "Epoch 37/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.1343 - mse: 2.1343 - val_loss: 12.0369 - val_mse: 12.0369\n",
      "Epoch 38/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.2556 - mse: 2.2556 - val_loss: 16.9852 - val_mse: 16.9852\n",
      "Epoch 39/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 4.6054 - mse: 4.6054 - val_loss: 15.4914 - val_mse: 15.4914\n",
      "Epoch 40/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 5.5392 - mse: 5.5392 - val_loss: 13.2282 - val_mse: 13.2282\n",
      "Epoch 41/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 5.3472 - mse: 5.3472 - val_loss: 15.6134 - val_mse: 15.6134\n",
      "Epoch 42/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.4918 - mse: 2.4918 - val_loss: 18.3007 - val_mse: 18.3007\n",
      "Epoch 43/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.2926 - mse: 2.2926 - val_loss: 15.5991 - val_mse: 15.5991\n",
      "Epoch 44/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.8625 - mse: 2.8625 - val_loss: 11.9533 - val_mse: 11.9533\n",
      "Epoch 45/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.0162 - mse: 2.0162 - val_loss: 13.6820 - val_mse: 13.6820\n",
      "Epoch 46/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.6437 - mse: 1.6437 - val_loss: 12.0874 - val_mse: 12.0874\n",
      "Epoch 47/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.4726 - mse: 1.4726 - val_loss: 12.8407 - val_mse: 12.8407\n",
      "Epoch 48/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.6531 - mse: 1.6531 - val_loss: 13.6041 - val_mse: 13.6041\n",
      "Epoch 49/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.6283 - mse: 1.6283 - val_loss: 14.0330 - val_mse: 14.0330\n",
      "Epoch 50/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.6479 - mse: 1.6479 - val_loss: 13.0421 - val_mse: 13.0421\n",
      "Epoch 51/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.4588 - mse: 1.4588 - val_loss: 15.9008 - val_mse: 15.9008\n",
      "Epoch 52/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.7370 - mse: 1.7370 - val_loss: 15.5603 - val_mse: 15.5603\n",
      "Epoch 53/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.5257 - mse: 1.5257 - val_loss: 14.0662 - val_mse: 14.0662\n",
      "Epoch 54/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.5724 - mse: 1.5724 - val_loss: 13.0425 - val_mse: 13.0425\n",
      "Epoch 55/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.2547 - mse: 2.2547 - val_loss: 16.3143 - val_mse: 16.3143\n",
      "Epoch 56/300\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 2.1155 - mse: 2.1155 - val_loss: 15.2347 - val_mse: 15.2347\n",
      "Epoch 57/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.9027 - mse: 1.9027 - val_loss: 16.4322 - val_mse: 16.4322\n",
      "Epoch 58/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.9335 - mse: 2.9335 - val_loss: 13.2535 - val_mse: 13.2535\n",
      "Epoch 59/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.7549 - mse: 1.7549 - val_loss: 14.0022 - val_mse: 14.0022\n",
      "Epoch 60/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.3465 - mse: 1.3465 - val_loss: 14.2141 - val_mse: 14.2141\n",
      "Epoch 61/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.2217 - mse: 1.2217 - val_loss: 13.5480 - val_mse: 13.5480\n",
      "Epoch 62/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.4400 - mse: 1.4400 - val_loss: 14.4399 - val_mse: 14.4399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.2934 - mse: 1.2934 - val_loss: 13.2148 - val_mse: 13.2148\n",
      "Epoch 64/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.3751 - mse: 2.3751 - val_loss: 13.2514 - val_mse: 13.2514\n",
      "Epoch 65/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.4457 - mse: 2.4457 - val_loss: 16.2960 - val_mse: 16.2960\n",
      "Epoch 66/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 3.6912 - mse: 3.6912 - val_loss: 20.6969 - val_mse: 20.6969\n",
      "Epoch 67/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 5.2413 - mse: 5.2413 - val_loss: 21.9245 - val_mse: 21.9245\n",
      "Epoch 68/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 6.1584 - mse: 6.1584 - val_loss: 9.2547 - val_mse: 9.2547\n",
      "Epoch 69/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 4.4243 - mse: 4.4243 - val_loss: 18.0729 - val_mse: 18.0729\n",
      "Epoch 70/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 3.9595 - mse: 3.9595 - val_loss: 11.3983 - val_mse: 11.3983\n",
      "Epoch 71/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.6646 - mse: 2.6646 - val_loss: 13.6436 - val_mse: 13.6436\n",
      "Epoch 72/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 4.9203 - mse: 4.9203 - val_loss: 19.7732 - val_mse: 19.7732\n",
      "Epoch 73/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 6.8024 - mse: 6.8024 - val_loss: 21.0258 - val_mse: 21.0258\n",
      "Epoch 74/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 6.2996 - mse: 6.2996 - val_loss: 16.4565 - val_mse: 16.4565\n",
      "Epoch 75/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 4.3967 - mse: 4.3967 - val_loss: 10.5011 - val_mse: 10.5011\n",
      "Epoch 76/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 3.1999 - mse: 3.1999 - val_loss: 13.5292 - val_mse: 13.5292\n",
      "Epoch 77/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 3.7183 - mse: 3.7183 - val_loss: 12.5632 - val_mse: 12.5632\n",
      "Epoch 78/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 3.2102 - mse: 3.2102 - val_loss: 16.9033 - val_mse: 16.9033\n",
      "Epoch 79/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 4.2346 - mse: 4.2346 - val_loss: 8.8670 - val_mse: 8.8670\n",
      "Epoch 80/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.6117 - mse: 2.6117 - val_loss: 12.5533 - val_mse: 12.5533\n",
      "Epoch 81/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.1974 - mse: 2.1974 - val_loss: 11.6404 - val_mse: 11.6404\n",
      "Epoch 82/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.8070 - mse: 1.8070 - val_loss: 13.1757 - val_mse: 13.1757\n",
      "Epoch 83/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.7883 - mse: 1.7883 - val_loss: 11.5325 - val_mse: 11.5325\n",
      "Epoch 84/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.5925 - mse: 1.5925 - val_loss: 12.4961 - val_mse: 12.4961\n",
      "Epoch 85/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.6676 - mse: 1.6676 - val_loss: 10.6806 - val_mse: 10.6806\n",
      "Epoch 86/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.6554 - mse: 1.6554 - val_loss: 10.9101 - val_mse: 10.9101\n",
      "Epoch 87/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.7769 - mse: 1.7769 - val_loss: 13.0128 - val_mse: 13.0128\n",
      "Epoch 88/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.0163 - mse: 2.0163 - val_loss: 12.0838 - val_mse: 12.0838\n",
      "Epoch 89/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.4223 - mse: 2.4223 - val_loss: 13.7972 - val_mse: 13.7972\n",
      "Epoch 90/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.6445 - mse: 2.6445 - val_loss: 13.4406 - val_mse: 13.4406\n",
      "Epoch 91/300\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 4.9013 - mse: 4.9013 - val_loss: 16.9869 - val_mse: 16.9869\n",
      "Epoch 92/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 3.4203 - mse: 3.4203 - val_loss: 19.2931 - val_mse: 19.2931\n",
      "Epoch 93/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 3.3451 - mse: 3.3451 - val_loss: 12.7281 - val_mse: 12.7281\n",
      "Epoch 94/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.6562 - mse: 2.6562 - val_loss: 9.9644 - val_mse: 9.9644\n",
      "Epoch 95/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.3202 - mse: 2.3202 - val_loss: 12.4184 - val_mse: 12.4184\n",
      "Epoch 96/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.8088 - mse: 1.8088 - val_loss: 11.9970 - val_mse: 11.9970\n",
      "Epoch 97/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.7229 - mse: 1.7229 - val_loss: 12.3104 - val_mse: 12.3104\n",
      "Epoch 98/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.4297 - mse: 1.4297 - val_loss: 11.7727 - val_mse: 11.7727\n",
      "Epoch 99/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.0031 - mse: 2.0031 - val_loss: 15.7355 - val_mse: 15.7355\n",
      "Epoch 100/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.0738 - mse: 2.0738 - val_loss: 11.5038 - val_mse: 11.5038\n",
      "Epoch 101/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.2705 - mse: 2.2705 - val_loss: 14.4137 - val_mse: 14.4137\n",
      "Epoch 102/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.3221 - mse: 2.3221 - val_loss: 13.3030 - val_mse: 13.3030\n",
      "Epoch 103/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 3.7572 - mse: 3.7572 - val_loss: 16.4349 - val_mse: 16.4349\n",
      "Epoch 104/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 3.9850 - mse: 3.9850 - val_loss: 15.9612 - val_mse: 15.9612\n",
      "Epoch 105/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 4.3872 - mse: 4.3872 - val_loss: 16.0985 - val_mse: 16.0985\n",
      "Epoch 106/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 3.3880 - mse: 3.3880 - val_loss: 14.1737 - val_mse: 14.1737\n",
      "Epoch 107/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 3.1201 - mse: 3.1201 - val_loss: 18.9688 - val_mse: 18.9688\n",
      "Epoch 108/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.9776 - mse: 2.9776 - val_loss: 13.0272 - val_mse: 13.0272\n",
      "Epoch 109/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.3188 - mse: 2.3188 - val_loss: 11.9409 - val_mse: 11.9409\n",
      "Epoch 110/300\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.7379 - mse: 1.7379 - val_loss: 11.7943 - val_mse: 11.7943\n",
      "Epoch 111/300\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 1.5233 - mse: 1.5233 - val_loss: 13.5340 - val_mse: 13.5340\n",
      "Epoch 112/300\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.5352 - mse: 1.5352 - val_loss: 15.5120 - val_mse: 15.5120\n",
      "Epoch 113/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.1099 - mse: 2.1099 - val_loss: 11.2689 - val_mse: 11.2689\n",
      "Epoch 114/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.2021 - mse: 2.2021 - val_loss: 13.9725 - val_mse: 13.9725\n",
      "Epoch 115/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.3339 - mse: 1.3339 - val_loss: 15.9334 - val_mse: 15.9334\n",
      "Epoch 116/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.4196 - mse: 1.4196 - val_loss: 14.4918 - val_mse: 14.4918\n",
      "Epoch 117/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.4163 - mse: 1.4163 - val_loss: 12.4996 - val_mse: 12.4996\n",
      "Epoch 118/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.3872 - mse: 1.3872 - val_loss: 14.3563 - val_mse: 14.3563\n",
      "Epoch 119/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.0682 - mse: 2.0682 - val_loss: 14.4579 - val_mse: 14.4579\n",
      "Epoch 120/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.6868 - mse: 1.6868 - val_loss: 14.9074 - val_mse: 14.9074\n",
      "Epoch 121/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.5008 - mse: 1.5008 - val_loss: 14.9586 - val_mse: 14.9586\n",
      "Epoch 122/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.6502 - mse: 1.6502 - val_loss: 19.0548 - val_mse: 19.0548\n",
      "Epoch 123/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 5.7635 - mse: 5.7635 - val_loss: 16.1022 - val_mse: 16.1022\n",
      "Epoch 124/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 4.8220 - mse: 4.8220 - val_loss: 17.1039 - val_mse: 17.1039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 125/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 4.8081 - mse: 4.8081 - val_loss: 17.3715 - val_mse: 17.3715\n",
      "Epoch 126/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.8992 - mse: 2.8992 - val_loss: 20.1098 - val_mse: 20.1098\n",
      "Epoch 127/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 3.0320 - mse: 3.0320 - val_loss: 13.9455 - val_mse: 13.9455\n",
      "Epoch 128/300\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 2.1993 - mse: 2.1993 - val_loss: 15.3382 - val_mse: 15.3382\n",
      "Epoch 129/300\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.7260 - mse: 1.7260 - val_loss: 16.2907 - val_mse: 16.2907\n",
      "Epoch 130/300\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.8320 - mse: 1.8320 - val_loss: 13.3374 - val_mse: 13.3374\n",
      "Epoch 131/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.6162 - mse: 1.6162 - val_loss: 15.6451 - val_mse: 15.6451\n",
      "Epoch 132/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.3550 - mse: 1.3550 - val_loss: 15.8020 - val_mse: 15.8020\n",
      "Epoch 133/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.3145 - mse: 1.3145 - val_loss: 15.2394 - val_mse: 15.2394\n",
      "Epoch 134/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0753 - mse: 1.0753 - val_loss: 14.1247 - val_mse: 14.1247\n",
      "Epoch 135/300\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.0946 - mse: 1.0946 - val_loss: 15.1456 - val_mse: 15.1456\n",
      "Epoch 136/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.1283 - mse: 1.1283 - val_loss: 14.0440 - val_mse: 14.0440\n",
      "Epoch 137/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.1228 - mse: 1.1228 - val_loss: 13.5463 - val_mse: 13.5463\n",
      "Epoch 138/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0029 - mse: 1.0029 - val_loss: 14.1705 - val_mse: 14.1705\n",
      "Epoch 139/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9737 - mse: 0.9737 - val_loss: 14.7613 - val_mse: 14.7613\n",
      "Epoch 140/300\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.1485 - mse: 1.1485 - val_loss: 13.5525 - val_mse: 13.5525\n",
      "Epoch 141/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.1524 - mse: 2.1524 - val_loss: 13.5216 - val_mse: 13.5216\n",
      "Epoch 142/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.3270 - mse: 1.3270 - val_loss: 13.7800 - val_mse: 13.7800\n",
      "Epoch 143/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.7757 - mse: 1.7757 - val_loss: 14.2912 - val_mse: 14.2912\n",
      "Epoch 144/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.7799 - mse: 1.7799 - val_loss: 16.0030 - val_mse: 16.0030\n",
      "Epoch 145/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.3364 - mse: 1.3364 - val_loss: 15.3252 - val_mse: 15.3252\n",
      "Epoch 146/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.3056 - mse: 1.3056 - val_loss: 14.2864 - val_mse: 14.2864\n",
      "Epoch 147/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.1750 - mse: 1.1750 - val_loss: 14.4988 - val_mse: 14.4988\n",
      "Epoch 148/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.2160 - mse: 1.2160 - val_loss: 14.7994 - val_mse: 14.7994\n",
      "Epoch 149/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.2057 - mse: 1.2057 - val_loss: 15.1153 - val_mse: 15.1153\n",
      "Epoch 150/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0319 - mse: 1.0319 - val_loss: 15.6258 - val_mse: 15.6258\n",
      "Epoch 151/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.2066 - mse: 1.2066 - val_loss: 14.8299 - val_mse: 14.8299\n",
      "Epoch 152/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.2910 - mse: 1.2910 - val_loss: 15.7671 - val_mse: 15.7671\n",
      "Epoch 153/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.2403 - mse: 1.2403 - val_loss: 12.5475 - val_mse: 12.5475\n",
      "Epoch 154/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.1888 - mse: 1.1888 - val_loss: 13.6544 - val_mse: 13.6544\n",
      "Epoch 155/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9774 - mse: 0.9774 - val_loss: 14.7934 - val_mse: 14.7934\n",
      "Epoch 156/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9784 - mse: 0.9784 - val_loss: 13.7963 - val_mse: 13.7963\n",
      "Epoch 157/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.4058 - mse: 1.4058 - val_loss: 15.3199 - val_mse: 15.3199\n",
      "Epoch 158/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.2572 - mse: 1.2572 - val_loss: 14.1375 - val_mse: 14.1375\n",
      "Epoch 159/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.0379 - mse: 1.0379 - val_loss: 14.9849 - val_mse: 14.9849\n",
      "Epoch 160/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9304 - mse: 0.9304 - val_loss: 15.3827 - val_mse: 15.3827\n",
      "Epoch 161/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.0442 - mse: 1.0442 - val_loss: 15.4086 - val_mse: 15.4086\n",
      "Epoch 162/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.1400 - mse: 1.1400 - val_loss: 14.7276 - val_mse: 14.7276\n",
      "Epoch 163/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9233 - mse: 0.9233 - val_loss: 15.4910 - val_mse: 15.4910\n",
      "Epoch 164/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9294 - mse: 0.9294 - val_loss: 15.0965 - val_mse: 15.0965\n",
      "Epoch 165/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.0652 - mse: 1.0652 - val_loss: 16.0482 - val_mse: 16.0482\n",
      "Epoch 166/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9653 - mse: 0.9653 - val_loss: 14.7715 - val_mse: 14.7715\n",
      "Epoch 167/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9860 - mse: 0.9860 - val_loss: 16.8363 - val_mse: 16.8363\n",
      "Epoch 168/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9534 - mse: 0.9534 - val_loss: 15.1916 - val_mse: 15.1916\n",
      "Epoch 169/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.8742 - mse: 0.8742 - val_loss: 15.5475 - val_mse: 15.5475\n",
      "Epoch 170/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8854 - mse: 0.8854 - val_loss: 14.4417 - val_mse: 14.4417\n",
      "Epoch 171/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8642 - mse: 0.8642 - val_loss: 15.2165 - val_mse: 15.2165\n",
      "Epoch 172/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.8036 - mse: 0.8036 - val_loss: 15.1864 - val_mse: 15.1864\n",
      "Epoch 173/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8361 - mse: 0.8361 - val_loss: 16.4460 - val_mse: 16.4460\n",
      "Epoch 174/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9010 - mse: 0.9010 - val_loss: 12.5104 - val_mse: 12.5104\n",
      "Epoch 175/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9055 - mse: 0.9055 - val_loss: 15.8410 - val_mse: 15.8410\n",
      "Epoch 176/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8227 - mse: 0.8227 - val_loss: 14.7489 - val_mse: 14.7489\n",
      "Epoch 177/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9548 - mse: 0.9548 - val_loss: 16.7955 - val_mse: 16.7955\n",
      "Epoch 178/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.1385 - mse: 1.1385 - val_loss: 12.5523 - val_mse: 12.5523\n",
      "Epoch 179/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.3755 - mse: 1.3755 - val_loss: 17.0838 - val_mse: 17.0838\n",
      "Epoch 180/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.1156 - mse: 1.1156 - val_loss: 14.7950 - val_mse: 14.7950\n",
      "Epoch 181/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9287 - mse: 0.9287 - val_loss: 16.6097 - val_mse: 16.6097\n",
      "Epoch 182/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.4731 - mse: 1.4731 - val_loss: 13.0226 - val_mse: 13.0226\n",
      "Epoch 183/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.3765 - mse: 1.3765 - val_loss: 16.0714 - val_mse: 16.0714\n",
      "Epoch 184/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9958 - mse: 0.9958 - val_loss: 15.7972 - val_mse: 15.7972\n",
      "Epoch 185/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.2182 - mse: 1.2182 - val_loss: 17.7050 - val_mse: 17.7050\n",
      "Epoch 186/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.3217 - mse: 1.3217 - val_loss: 14.3552 - val_mse: 14.3552\n",
      "Epoch 187/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 3.0841 - mse: 3.0841 - val_loss: 17.2077 - val_mse: 17.2077\n",
      "Epoch 188/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.8066 - mse: 1.8066 - val_loss: 17.5480 - val_mse: 17.5480\n",
      "Epoch 189/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.5154 - mse: 1.5154 - val_loss: 14.2103 - val_mse: 14.2103\n",
      "Epoch 190/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.3214 - mse: 1.3214 - val_loss: 24.3759 - val_mse: 24.3759\n",
      "Epoch 191/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 3.5595 - mse: 3.5595 - val_loss: 18.4471 - val_mse: 18.4471\n",
      "Epoch 192/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.6578 - mse: 1.6578 - val_loss: 14.7688 - val_mse: 14.7688\n",
      "Epoch 193/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.5614 - mse: 1.5614 - val_loss: 12.3396 - val_mse: 12.3396\n",
      "Epoch 194/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.3629 - mse: 1.3629 - val_loss: 14.9207 - val_mse: 14.9207\n",
      "Epoch 195/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.0100 - mse: 1.0100 - val_loss: 12.8751 - val_mse: 12.8751\n",
      "Epoch 196/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.2452 - mse: 1.2452 - val_loss: 15.4965 - val_mse: 15.4965\n",
      "Epoch 197/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.3587 - mse: 1.3587 - val_loss: 14.9375 - val_mse: 14.9375\n",
      "Epoch 198/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9182 - mse: 0.9182 - val_loss: 17.1907 - val_mse: 17.1907\n",
      "Epoch 199/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.4063 - mse: 1.4063 - val_loss: 16.6759 - val_mse: 16.6759\n",
      "Epoch 200/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.1735 - mse: 1.1735 - val_loss: 15.5684 - val_mse: 15.5684\n",
      "Epoch 201/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9613 - mse: 0.9613 - val_loss: 14.0390 - val_mse: 14.0390\n",
      "Epoch 202/300\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 1.2339 - mse: 1.2339 - val_loss: 17.3813 - val_mse: 17.3813\n",
      "Epoch 203/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.4425 - mse: 1.4425 - val_loss: 13.5007 - val_mse: 13.5007\n",
      "Epoch 204/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.5582 - mse: 1.5582 - val_loss: 14.3021 - val_mse: 14.3021\n",
      "Epoch 205/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.3544 - mse: 1.3544 - val_loss: 18.1627 - val_mse: 18.1627\n",
      "Epoch 206/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.1203 - mse: 1.1203 - val_loss: 18.0842 - val_mse: 18.0842\n",
      "Epoch 207/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.8537 - mse: 1.8537 - val_loss: 16.8712 - val_mse: 16.8712\n",
      "Epoch 208/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.5885 - mse: 1.5885 - val_loss: 18.7472 - val_mse: 18.7472\n",
      "Epoch 209/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.1796 - mse: 1.1796 - val_loss: 15.7004 - val_mse: 15.7004\n",
      "Epoch 210/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.2144 - mse: 1.2144 - val_loss: 19.5844 - val_mse: 19.5844\n",
      "Epoch 211/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.2307 - mse: 1.2307 - val_loss: 15.7900 - val_mse: 15.7900\n",
      "Epoch 212/300\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.9968 - mse: 0.9968 - val_loss: 16.6230 - val_mse: 16.6230\n",
      "Epoch 213/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.8888 - mse: 0.8888 - val_loss: 15.4603 - val_mse: 15.4603\n",
      "Epoch 214/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.9201 - mse: 0.9201 - val_loss: 16.9691 - val_mse: 16.9691\n",
      "Epoch 215/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8998 - mse: 0.8998 - val_loss: 14.4203 - val_mse: 14.4203\n",
      "Epoch 216/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.9588 - mse: 0.9588 - val_loss: 17.2164 - val_mse: 17.2164\n",
      "Epoch 217/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.7854 - mse: 0.7854 - val_loss: 15.0125 - val_mse: 15.0125\n",
      "Epoch 218/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.8224 - mse: 0.8224 - val_loss: 15.9822 - val_mse: 15.9822\n",
      "Epoch 219/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.8850 - mse: 0.8850 - val_loss: 15.6852 - val_mse: 15.6852\n",
      "Epoch 220/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.5679 - mse: 1.5679 - val_loss: 16.5577 - val_mse: 16.5577\n",
      "Epoch 221/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.3592 - mse: 1.3592 - val_loss: 16.7017 - val_mse: 16.7017\n",
      "Epoch 222/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.1346 - mse: 1.1346 - val_loss: 14.1683 - val_mse: 14.1683\n",
      "Epoch 223/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.2990 - mse: 1.2990 - val_loss: 20.2331 - val_mse: 20.2331\n",
      "Epoch 224/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 1.5351 - mse: 1.5351 - val_loss: 15.2737 - val_mse: 15.2737\n",
      "Epoch 225/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9424 - mse: 0.9424 - val_loss: 18.2456 - val_mse: 18.2456\n",
      "Epoch 226/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.6071 - mse: 1.6071 - val_loss: 12.7211 - val_mse: 12.7211\n",
      "Epoch 227/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.6040 - mse: 1.6040 - val_loss: 17.2929 - val_mse: 17.2929\n",
      "Epoch 228/300\n",
      "7/7 [==============================] - ETA: 0s - loss: 1.1768 - mse: 1.176 - 0s 8ms/step - loss: 1.6742 - mse: 1.6742 - val_loss: 18.7924 - val_mse: 18.7924\n",
      "Epoch 229/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.0101 - mse: 2.0101 - val_loss: 14.2002 - val_mse: 14.2002\n",
      "Epoch 230/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.0708 - mse: 2.0708 - val_loss: 17.0558 - val_mse: 17.0558\n",
      "Epoch 231/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.2713 - mse: 1.2713 - val_loss: 15.0741 - val_mse: 15.0741\n",
      "Epoch 232/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.3351 - mse: 2.3351 - val_loss: 15.6765 - val_mse: 15.6765\n",
      "Epoch 233/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.7095 - mse: 1.7095 - val_loss: 19.5823 - val_mse: 19.5823\n",
      "Epoch 234/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.0708 - mse: 2.0708 - val_loss: 16.1773 - val_mse: 16.1773\n",
      "Epoch 235/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.1169 - mse: 2.1169 - val_loss: 17.7255 - val_mse: 17.7255\n",
      "Epoch 236/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.6257 - mse: 1.6257 - val_loss: 12.8385 - val_mse: 12.8385\n",
      "Epoch 237/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.3101 - mse: 1.3101 - val_loss: 16.8089 - val_mse: 16.8089\n",
      "Epoch 238/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.2358 - mse: 1.2358 - val_loss: 13.9098 - val_mse: 13.9098\n",
      "Epoch 239/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.0821 - mse: 1.0821 - val_loss: 15.9269 - val_mse: 15.9269\n",
      "Epoch 240/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.1219 - mse: 2.1219 - val_loss: 15.3047 - val_mse: 15.3047\n",
      "Epoch 241/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.0372 - mse: 2.0372 - val_loss: 15.8939 - val_mse: 15.8939\n",
      "Epoch 242/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.1724 - mse: 2.1724 - val_loss: 15.0328 - val_mse: 15.0328\n",
      "Epoch 243/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.7423 - mse: 1.7423 - val_loss: 15.0336 - val_mse: 15.0336\n",
      "Epoch 244/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.3303 - mse: 1.3303 - val_loss: 18.0747 - val_mse: 18.0747\n",
      "Epoch 245/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.5032 - mse: 1.5032 - val_loss: 17.0042 - val_mse: 17.0042\n",
      "Epoch 246/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.4856 - mse: 1.4856 - val_loss: 20.2382 - val_mse: 20.2382\n",
      "Epoch 247/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 8ms/step - loss: 2.2526 - mse: 2.2526 - val_loss: 15.7351 - val_mse: 15.7351\n",
      "Epoch 248/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.3584 - mse: 1.3584 - val_loss: 16.2071 - val_mse: 16.2071\n",
      "Epoch 249/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0207 - mse: 1.0207 - val_loss: 16.5882 - val_mse: 16.5882\n",
      "Epoch 250/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.9413 - mse: 0.9413 - val_loss: 13.9241 - val_mse: 13.9241\n",
      "Epoch 251/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.0911 - mse: 1.0911 - val_loss: 18.2979 - val_mse: 18.2979\n",
      "Epoch 252/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.3887 - mse: 1.3887 - val_loss: 15.0843 - val_mse: 15.0843\n",
      "Epoch 253/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.0715 - mse: 1.0715 - val_loss: 16.2130 - val_mse: 16.2130\n",
      "Epoch 254/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.9364 - mse: 1.9364 - val_loss: 12.8423 - val_mse: 12.8423\n",
      "Epoch 255/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 6.1696 - mse: 6.1696 - val_loss: 17.3901 - val_mse: 17.3901\n",
      "Epoch 256/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.9406 - mse: 2.9406 - val_loss: 22.7697 - val_mse: 22.7697\n",
      "Epoch 257/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 4.4564 - mse: 4.4564 - val_loss: 11.9456 - val_mse: 11.9456\n",
      "Epoch 258/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.5756 - mse: 2.5756 - val_loss: 14.7385 - val_mse: 14.7385\n",
      "Epoch 259/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.8977 - mse: 1.8977 - val_loss: 15.1854 - val_mse: 15.1854\n",
      "Epoch 260/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.7297 - mse: 2.7297 - val_loss: 13.5768 - val_mse: 13.5768\n",
      "Epoch 261/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 3.1325 - mse: 3.1325 - val_loss: 13.6552 - val_mse: 13.6552\n",
      "Epoch 262/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 3.5631 - mse: 3.5631 - val_loss: 18.4753 - val_mse: 18.4753\n",
      "Epoch 263/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.4529 - mse: 2.4529 - val_loss: 21.8581 - val_mse: 21.8581\n",
      "Epoch 264/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 3.0267 - mse: 3.0267 - val_loss: 15.0021 - val_mse: 15.0021\n",
      "Epoch 265/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.8517 - mse: 1.8517 - val_loss: 16.4758 - val_mse: 16.4758\n",
      "Epoch 266/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.2979 - mse: 1.2979 - val_loss: 15.0490 - val_mse: 15.0490\n",
      "Epoch 267/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.7710 - mse: 1.7710 - val_loss: 16.8589 - val_mse: 16.8589\n",
      "Epoch 268/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.2886 - mse: 1.2886 - val_loss: 13.1617 - val_mse: 13.1617\n",
      "Epoch 269/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.3623 - mse: 1.3623 - val_loss: 15.4606 - val_mse: 15.4606\n",
      "Epoch 270/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.2895 - mse: 1.2895 - val_loss: 14.4087 - val_mse: 14.4087\n",
      "Epoch 271/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.2319 - mse: 1.2319 - val_loss: 17.4510 - val_mse: 17.4510\n",
      "Epoch 272/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.8290 - mse: 1.8290 - val_loss: 13.2854 - val_mse: 13.2854\n",
      "Epoch 273/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.3636 - mse: 1.3636 - val_loss: 15.7445 - val_mse: 15.7445\n",
      "Epoch 274/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.1557 - mse: 1.1557 - val_loss: 13.9574 - val_mse: 13.9574\n",
      "Epoch 275/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 1.1565 - mse: 1.1565 - val_loss: 15.8977 - val_mse: 15.8977\n",
      "Epoch 276/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.2927 - mse: 2.2927 - val_loss: 11.4313 - val_mse: 11.4313\n",
      "Epoch 277/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.2751 - mse: 2.2751 - val_loss: 8.9298 - val_mse: 8.9298\n",
      "Epoch 278/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 2.5627 - mse: 2.5627 - val_loss: 11.8345 - val_mse: 11.8345\n",
      "Epoch 279/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 3.0124 - mse: 3.0124 - val_loss: 10.6196 - val_mse: 10.6196\n",
      "Epoch 280/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.8480 - mse: 1.8480 - val_loss: 17.6608 - val_mse: 17.6608\n",
      "Epoch 281/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 3.4895 - mse: 3.4895 - val_loss: 14.9723 - val_mse: 14.9723\n",
      "Epoch 282/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.5041 - mse: 2.5041 - val_loss: 16.3480 - val_mse: 16.3480\n",
      "Epoch 283/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 11.2073 - mse: 11.2073 - val_loss: 8.0075 - val_mse: 8.0075\n",
      "Epoch 284/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 8.4751 - mse: 8.4751 - val_loss: 12.9541 - val_mse: 12.9541\n",
      "Epoch 285/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 17.1811 - mse: 17.1811 - val_loss: 23.6850 - val_mse: 23.6850\n",
      "Epoch 286/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 11.3978 - mse: 11.3978 - val_loss: 9.2260 - val_mse: 9.2260\n",
      "Epoch 287/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 7.1541 - mse: 7.1541 - val_loss: 12.7048 - val_mse: 12.7048\n",
      "Epoch 288/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 4.0501 - mse: 4.0501 - val_loss: 14.5631 - val_mse: 14.5631\n",
      "Epoch 289/300\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 4.0172 - mse: 4.0172 - val_loss: 14.3699 - val_mse: 14.3699\n",
      "Epoch 290/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.7018 - mse: 2.7018 - val_loss: 12.4044 - val_mse: 12.4044\n",
      "Epoch 291/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.6322 - mse: 2.6322 - val_loss: 10.0779 - val_mse: 10.0779\n",
      "Epoch 292/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.4428 - mse: 2.4428 - val_loss: 10.1465 - val_mse: 10.1465\n",
      "Epoch 293/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.9232 - mse: 1.9232 - val_loss: 10.2418 - val_mse: 10.2418\n",
      "Epoch 294/300\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 2.8256 - mse: 2.8256 - val_loss: 14.0622 - val_mse: 14.0622\n",
      "Epoch 295/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.0052 - mse: 2.0052 - val_loss: 10.6636 - val_mse: 10.6636\n",
      "Epoch 296/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 6.0739 - mse: 6.0739 - val_loss: 8.3745 - val_mse: 8.3745\n",
      "Epoch 297/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 6.4178 - mse: 6.4178 - val_loss: 11.8724 - val_mse: 11.8724\n",
      "Epoch 298/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 3.9483 - mse: 3.9483 - val_loss: 13.3235 - val_mse: 13.3235\n",
      "Epoch 299/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 2.4003 - mse: 2.4003 - val_loss: 14.8323 - val_mse: 14.8323\n",
      "Epoch 300/300\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 1.8522 - mse: 1.8522 - val_loss: 11.6214 - val_mse: 11.6214\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size = 50, epochs = 300, validation_data = (X_val, y_val), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 2210049.0000 - mse: 2210049.0000\n",
      "loss : 2210049.0\n",
      "mse  : 2210049.0\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(X_test, y_test)\n",
    "print ('loss :', result[0])\n",
    "print ('mse  :', result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
